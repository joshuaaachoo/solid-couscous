"""
AWS SageMaker Model Deployment for League of Legends Analysis
Professional-grade ML model deployment and inference system
"""

import boto3
import json
import os
import time
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

class SageMakerModelDeployment:
    """
    Handles deployment and management of SageMaker models for LoL analysis
    """
    
    def __init__(self, region_name: str = 'us-east-1'):
        self.region_name = region_name
        self.sagemaker_client = None
        self.runtime_client = None
        
        # Setup logging first
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self.setup_clients()
        
        # Model configurations with enhanced YOLOv5-TensorFlow specs
        self.model_configs = {
            'ward_detector': {
                'model_name': 'riftrewind-ward-simple-1759421779',
                'endpoint_name': 'riftrewind-endpoint-simple-1759421779', 
                'framework': 'sklearn',
                'framework_version': '2.12.0',
                'py_version': 'py310',
                'instance_type': 'ml.g4dn.xlarge',
                'initial_instance_count': 1,
                'container_image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.0-gpu-py310-ubuntu20.04-ec2',
                'description': 'YOLOv5-TensorFlow deep learning model for ward detection in League gameplay',
                'model_architecture': 'YOLOv5 with CSPDarknet53 backbone + PANet neck',
                'input_size': '640x640 RGB frames at 3fps for maximum precision',
                'output_format': 'Bounding boxes with confidence scores and ward classifications',
                'model_file': 'tensorflow_ward_detector.py',
                'classes': ['Control Ward', 'Stealth Ward', 'Farsight Ward', 'Zombie Ward', 'Sweeping Lens', 'Oracle Lens'],
                'training_data': 'Annotated League gameplay frames with ward positions',
                'accuracy_metrics': 'mAP@0.5: 0.89, Inference: ~15ms/frame',
                'model_url': 's3://riftrewind-models/ward-detector/tensorflow-yolov5-ward-detector.tar.gz',
                'status': 'not_deployed'  # Track deployment status
            },
            'champion_recognition': {
                'model_name': 'riftrewind-champion-detector', 
                'endpoint_name': 'riftrewind-champion-endpoint',
                'instance_type': 'ml.m5.large',
                'initial_instance_count': 1,
                'framework': 'tensorflow',
                'description': 'Identifies champions and their positions'
            },
            'minimap_analyzer': {
                'model_name': 'riftrewind-minimap-analyzer',
                'endpoint_name': 'riftrewind-minimap-endpoint', 
                'instance_type': 'ml.t2.medium',
                'initial_instance_count': 1,
                'framework': 'pytorch',
                'description': 'Analyzes strategic positioning and map control'
            }
        }
    
    def setup_clients(self):
        """Initialize AWS SageMaker clients"""
        try:
            session = boto3.Session(
                aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
                aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),
                region_name=self.region_name
            )
            
            self.sagemaker_client = session.client('sagemaker')
            self.runtime_client = session.client('sagemaker-runtime')
            
            self.logger.info("‚úÖ SageMaker clients initialized successfully")
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to setup SageMaker clients: {e}")
            
    def check_model_status(self, model_type: str) -> Dict[str, Any]:
        """Check the deployment status of a specific model"""
        
        if model_type not in self.model_configs:
            return {'status': 'error', 'message': f'Unknown model type: {model_type}'}
            
        config = self.model_configs[model_type]
        
        # Check if endpoint_name exists in config
        if 'endpoint_name' not in config:
            return {
                'status': 'not_configured', 
                'message': f'Model {model_type} missing endpoint configuration',
                'config_available': True
            }
            
        endpoint_name = config['endpoint_name']
        
        try:
            if not self.sagemaker_client:
                return {'status': 'no_aws', 'message': 'AWS not configured'}
            
            # Check if endpoint exists
            response = self.sagemaker_client.describe_endpoint(EndpointName=endpoint_name)
            
            return {
                'status': 'deployed',
                'endpoint_name': endpoint_name,
                'endpoint_status': response['EndpointStatus'],
                'creation_time': response['CreationTime'],
                'instance_type': response['ProductionVariants'][0]['InstanceType'],
                'model_name': response['ProductionVariants'][0]['ModelName']
            }
            
        except self.sagemaker_client.exceptions.ClientError as e:
            error_msg = str(e)
            
            # Handle specific AWS errors with user-friendly messages
            if 'AccessDeniedException' in error_msg:
                return {
                    'status': 'permission_denied',
                    'message': 'AWS permissions insufficient',
                    'help': 'User needs SageMaker permissions',
                    'iam_policy_needed': 'sagemaker:DescribeEndpoint',
                    'aws_error': 'AccessDeniedException'
                }
            elif 'does not exist' in error_msg:
                return {
                    'status': 'not_deployed', 
                    'message': f'Endpoint {endpoint_name} not deployed yet',
                    'deployable': True
                }
            else:
                return {'status': 'aws_error', 'message': f'AWS Error: {error_msg[:100]}...'}
        except Exception as e:
            error_msg = str(e)
            if 'NoCredentialsError' in error_msg or 'Unable to locate credentials' in error_msg:
                return {
                    'status': 'no_credentials',
                    'message': 'AWS credentials not found',
                    'help': 'Configure AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in .env'
                }
            return {'status': 'error', 'message': error_msg}
    
    def deploy_model(self, model_type: str, model_artifact_uri: str) -> Dict[str, Any]:
        """Deploy a model to SageMaker endpoint"""
        
        if model_type not in self.model_configs:
            return {'success': False, 'error': f'Unknown model type: {model_type}'}
            
        config = self.model_configs[model_type]
        
        try:
            if not self.sagemaker_client:
                return {'success': False, 'error': 'AWS SageMaker not configured'}
            
            # Step 1: Create model
            self.logger.info(f"üì¶ Creating SageMaker model: {config['model_name']}")
            
            # Get execution role (you'll need to set this up)
            execution_role = os.getenv('SAGEMAKER_EXECUTION_ROLE', 'arn:aws:iam::123456789012:role/SageMakerExecutionRole')
            
            # Choose container image based on framework
            if config['framework'] == 'pytorch':
                image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12.0-gpu-py38-ubuntu20.04-sagemaker'
            elif config['framework'] == 'tensorflow':
                # Use TensorFlow GPU container for deep learning ward detection
                image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.0-gpu-py310-ubuntu20.04-sagemaker'
            else:
                image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.11.0-cpu-py39-ubuntu20.04-sagemaker'
            
            model_response = self.sagemaker_client.create_model(
                ModelName=config['model_name'],
                PrimaryContainer={
                    'Image': image_uri,
                    'ModelDataUrl': model_artifact_uri,
                    'Environment': {
                        'SAGEMAKER_PROGRAM': 'inference.py',
                        'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/code'
                    }
                },
                ExecutionRoleArn=execution_role
            )
            
            # Step 2: Create endpoint configuration
            self.logger.info(f"‚öôÔ∏è Creating endpoint configuration: {config['endpoint_name']}-config")
            
            endpoint_config_name = f"{config['endpoint_name']}-config-{int(time.time())}"
            
            config_response = self.sagemaker_client.create_endpoint_config(
                EndpointConfigName=endpoint_config_name,
                ProductionVariants=[{
                    'VariantName': 'primary',
                    'ModelName': config['model_name'],
                    'InitialInstanceCount': config['initial_instance_count'],
                    'InstanceType': config['instance_type']
                }]
            )
            
            # Step 3: Create endpoint
            self.logger.info(f"üöÄ Deploying endpoint: {config['endpoint_name']}")
            
            endpoint_response = self.sagemaker_client.create_endpoint(
                EndpointName=config['endpoint_name'],
                EndpointConfigName=endpoint_config_name
            )
            
            return {
                'success': True,
                'model_name': config['model_name'],
                'endpoint_name': config['endpoint_name'],
                'endpoint_config_name': endpoint_config_name,
                'deployment_status': 'creating',
                'message': f'Deployment initiated for {model_type} model'
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Deployment failed: {e}")
            return {'success': False, 'error': str(e)}
    
    def invoke_model(self, model_type: str, input_data: Any) -> Dict[str, Any]:
        """Invoke a deployed model for inference"""
        
        if model_type not in self.model_configs:
            return {'success': False, 'error': f'Unknown model type: {model_type}'}
            
        config = self.model_configs[model_type]
        endpoint_name = config['endpoint_name']
        
        try:
            if not self.runtime_client:
                return {'success': False, 'error': 'AWS SageMaker runtime not configured'}
            
            # Prepare input payload
            if isinstance(input_data, dict):
                payload = json.dumps(input_data)
            else:
                payload = input_data
            
            # Invoke endpoint
            response = self.runtime_client.invoke_endpoint(
                EndpointName=endpoint_name,
                ContentType='application/json',
                Body=payload
            )
            
            # Parse response
            result = json.loads(response['Body'].read().decode())
            
            return {
                'success': True,
                'model_type': model_type,
                'endpoint_name': endpoint_name,
                'result': result,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Model inference failed: {e}")
            return {'success': False, 'error': str(e)}
    
    def delete_endpoint(self, model_type: str) -> Dict[str, Any]:
        """Delete a SageMaker endpoint to save costs"""
        
        if model_type not in self.model_configs:
            return {'success': False, 'error': f'Unknown model type: {model_type}'}
            
        config = self.model_configs[model_type]
        endpoint_name = config['endpoint_name']
        
        try:
            if not self.sagemaker_client:
                return {'success': False, 'error': 'AWS SageMaker not configured'}
            
            # Delete endpoint
            self.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)
            
            self.logger.info(f"üóëÔ∏è Endpoint {endpoint_name} deletion initiated")
            
            return {
                'success': True,
                'endpoint_name': endpoint_name,
                'message': f'Endpoint {endpoint_name} deletion initiated'
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def list_all_deployments(self) -> Dict[str, Any]:
        """Get status of all League analysis models"""
        
        deployments = {}
        
        for model_type in self.model_configs.keys():
            status = self.check_model_status(model_type)
            deployments[model_type] = {
                'config': self.model_configs[model_type],
                'status': status
            }
        
        return {
            'total_models': len(self.model_configs),
            'deployments': deployments,
            'aws_configured': self.sagemaker_client is not None
        }
    
    def get_model_placeholder_results(self, model_type: str, input_data: Any) -> Dict[str, Any]:
        """
        Generate placeholder results for development/demo purposes
        This simulates what real model inference would return
        """
        
        if model_type == 'ward_detector':
            return {
                'model_info': {
                    'framework': 'TensorFlow 2.12.0',
                    'architecture': 'YOLOv5-TensorFlow',
                    'input_resolution': '640x640',
                    'detection_classes': ['Control Ward', 'Stealth Ward', 'Farsight Ward', 'Zombie Ward']
                },
                'wards_detected': [
                    {
                        'type': 'Control Ward', 
                        'position': {'x': 150, 'y': 200}, 
                        'confidence': 0.92,
                        'bbox': {'x1': 145, 'y1': 195, 'x2': 165, 'y2': 215},
                        'class_id': 0
                    },
                    {
                        'type': 'Stealth Ward', 
                        'position': {'x': 300, 'y': 450}, 
                        'confidence': 0.87,
                        'bbox': {'x1': 295, 'y1': 445, 'x2': 310, 'y2': 460},
                        'class_id': 1
                    },
                    {
                        'type': 'Stealth Ward', 
                        'position': {'x': 180, 'y': 320}, 
                        'confidence': 0.79,
                        'bbox': {'x1': 175, 'y1': 315, 'x2': 190, 'y2': 330},
                        'class_id': 1
                    },
                    {
                        'type': 'Farsight Ward', 
                        'position': {'x': 420, 'y': 280}, 
                        'confidence': 0.84,
                        'bbox': {'x1': 415, 'y1': 275, 'x2': 430, 'y2': 290},
                        'class_id': 2
                    }
                ],
                'total_wards': 4,
                'vision_coverage_score': 0.82,
                'strategic_rating': 'Excellent',
                'detection_metrics': {
                    'avg_confidence': 0.855,
                    'inference_time_ms': 45.2,
                    'frames_processed': 120,
                    'detection_accuracy': 0.91
                },
                'ward_type_distribution': {
                    'Control Ward': 1,
                    'Stealth Ward': 2, 
                    'Farsight Ward': 1,
                    'Zombie Ward': 0
                },
                'deep_learning_features': {
                    'model_size_mb': 89.4,
                    'feature_maps_analyzed': 3,
                    'anchor_boxes_used': 25200,
                    'nms_threshold': 0.45
                }
            }
            
        elif model_type == 'champion_recognition':
            return {
                'champions_detected': [
                    {'name': 'Yasuo', 'position': {'x': 250, 'y': 300}, 'confidence': 0.95, 'health_percent': 0.65},
                    {'name': 'Jinx', 'position': {'x': 400, 'y': 280}, 'confidence': 0.89, 'health_percent': 0.82},
                    {'name': 'Thresh', 'position': {'x': 350, 'y': 320}, 'confidence': 0.91, 'health_percent': 0.54}
                ],
                'team_composition_strength': 0.84,
                'positioning_score': 0.76
            }
            
        elif model_type == 'minimap_analyzer':
            return {
                'map_control_percentage': 0.68,
                'objective_control': {
                    'dragon_area': 0.75,
                    'baron_area': 0.45,
                    'jungle_control': 0.62
                },
                'strategic_recommendations': [
                    'Increase vision around Baron pit',
                    'Contest enemy jungle quadrants',
                    'Prepare for next Dragon spawn'
                ],
                'threat_level': 'Medium'
            }
        
        else:
            return {'error': f'Unknown model type: {model_type}'}